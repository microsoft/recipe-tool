# This file was generated by Codebase-Generator, do not edit directly
import asyncio
import logging
from typing import Any, Dict, List, Optional, Union

from recipe_executor.steps.base import BaseStep, StepConfig
from recipe_executor.protocols import ContextProtocol
from recipe_executor.utils.templates import render_template


class LoopStepConfig(StepConfig):
    """
    Configuration for LoopStep.

    Fields:
        items: Either string that resolves to a collection in the context (e.g., "data.items") or a list/dict.
        item_key: Key to use when storing the current item in each iteration's context.
        max_concurrency: Maximum number of items to process concurrently. Default = 1.
        delay: Time in seconds to wait between starting each parallel task. Default = 0.0.
        substeps: List of sub-step configurations to execute for each item.
        result_key: Key to store the collection of results in the context.
        fail_fast: Whether to stop processing on the first error.
    """

    items: Union[str, List[Any], Dict[str, Any]]
    item_key: str
    max_concurrency: int = 1
    delay: float = 0.0
    substeps: List[Dict[str, Any]]
    result_key: str
    fail_fast: bool = True


class LoopStep(BaseStep[LoopStepConfig]):
    def __init__(self, logger: logging.Logger, config: Any) -> None:
        validated = LoopStepConfig.model_validate(config)
        super().__init__(logger, validated)

    async def execute(self, context: ContextProtocol) -> None:
        # Resolve items collection
        raw = self.config.items
        if isinstance(raw, str):
            path = render_template(raw, context)
            data = context.dict()
            for part in path.split("."):
                if not isinstance(data, dict) or part not in data:
                    raise ValueError(f"LoopStep: path '{path}' not found in context")
                data = data[part]
            collection = data
        else:
            collection = raw

        # Determine iteration type
        is_dict = isinstance(collection, dict)
        items = collection.items() if is_dict else list(collection)
        total = len(collection) if hasattr(collection, "__len__") else 0
        self.logger.info(f"LoopStep: starting loop over {total} items")

        # Handle empty collection
        if total == 0:
            result_coll = {} if is_dict else []
            context[self.config.result_key] = result_coll
            return

        # Prepare result container
        results: List[Any] = []
        errors: List[Dict[str, Any]] = []

        # Sequential processing if no parallelism
        if self.config.max_concurrency == 1:
            for idx, entry in enumerate(items):
                key, item = entry if is_dict else (idx, entry)
                try:
                    self.logger.debug(f"LoopStep: processing item {key}")
                    res = await self._process_item(key, item, context)
                    results.append(res)
                    self.logger.debug(f"LoopStep: finished item {key}")
                except Exception as e:
                    self.logger.error(f"LoopStep: error on item {key}: {e}")
                    if self.config.fail_fast:
                        raise
                    errors.append({"key" if is_dict else "index": key, "error": str(e)})
        else:
            # Parallel or unlimited processing
            sem: Optional[asyncio.Semaphore]
            if self.config.max_concurrency > 0:
                sem = asyncio.Semaphore(self.config.max_concurrency)
            else:
                sem = None

            async def worker(key: Any, item: Any) -> Any:
                if sem:
                    await sem.acquire()
                try:
                    self.logger.debug(f"LoopStep: processing item {key}")
                    res = await self._process_item(key, item, context)
                    self.logger.debug(f"LoopStep: finished item {key}")
                    return res
                finally:
                    if sem:
                        sem.release()

            tasks = []
            for idx, entry in enumerate(items):
                key, item = entry if is_dict else (idx, entry)
                task = asyncio.create_task(worker(key, item))
                tasks.append((key, task))
                if self.config.delay and idx < total - 1:
                    await asyncio.sleep(self.config.delay)

            # Gather results
            if self.config.fail_fast:
                try:
                    for key, task in tasks:
                        results.append(await task)
                except Exception as e:
                    # cancel pending tasks
                    for _, t in tasks:
                        if not t.done():
                            t.cancel()
                    self.logger.error(f"LoopStep: fail-fast, cancelling. Error: {e}")
                    raise
            else:
                for key, task in tasks:
                    try:
                        res = await task
                        results.append(res)
                    except Exception as e:
                        self.logger.error(f"LoopStep: error on item {key}: {e}")
                        errors.append({"key" if is_dict else "index": key, "error": str(e)})

        # Store results
        if is_dict:
            # reconstruct dict by order
            context[self.config.result_key] = {
                (entry if not isinstance(entry, tuple) else entry[0]): res for entry, res in zip(items, results)
            }
        else:
            context[self.config.result_key] = results

        if errors:
            # Attach errors info
            err_key = f"{self.config.result_key}__errors"
            context[err_key] = errors

    async def _process_item(self, key: Any, item: Any, parent_context: ContextProtocol) -> Any:
        # Clone context for isolation
        ctx = parent_context.clone()
        # Set item and metadata
        ctx[self.config.item_key] = item
        if isinstance(key, int):
            ctx["__index"] = key
        else:
            ctx["__key"] = key
        # Execute sub-steps as a recipe
        from recipe_executor.executor import Executor

        executor = Executor(self.logger)
        recipe = {"steps": self.config.substeps}
        await executor.execute(recipe, ctx)
        # Extract item result
        return ctx.get(self.config.item_key)
